{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"> \n",
    "    <h1 align=\"center\">Predicting the Game Outcome for a Team in League of Legends</h1>\n",
    "    <h5 align=\"center\">John Bang, SJ Yu</h5>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "summonerIds = []\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "\n",
    "# Challenger League\n",
    "CHAL_URL = \"https://na1.api.riotgames.com/lol/league/v4/challengerleagues/by-queue/RANKED_SOLO_5x5\"\n",
    "chal_response = requests.get(CHAL_URL, headers={'X-Riot-Token': API_KEY})\n",
    "\n",
    "# Get the summonerID for each player in the Challenger league\n",
    "entries = chal_response.json()['entries']\n",
    "for entry in entries:\n",
    "    summonerIds.append(entry['summonerId'])\n",
    "\n",
    "# Grandmaster League\n",
    "GM_URL = \"https://na1.api.riotgames.com/lol/league/v4/challengerleagues/by-queue/RANKED_SOLO_5x5\"\n",
    "gm_response = requests.get(GM_URL, headers={'X-Riot-Token': API_KEY})\n",
    "\n",
    "# Get the summonerID for each player in the Grandmaster league\n",
    "entries = gm_response.json()['entries']\n",
    "for entry in entries:\n",
    "    summonerIds.append(entry['summonerId'])\n",
    "\n",
    "# Master League\n",
    "M_URL = \"https://na1.api.riotgames.com/lol/league/v4/challengerleagues/by-queue/RANKED_SOLO_5x5\"\n",
    "m_response = requests.get(M_URL, headers={'X-Riot-Token': API_KEY})\n",
    "\n",
    "# Get the summonerID for each player in the Master league\n",
    "entries = m_response.json()['entries']\n",
    "for entry in entries:\n",
    "    summonerIds.append(entry['summonerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened file puuids.txt\n"
     ]
    }
   ],
   "source": [
    "puuids = []\n",
    "\n",
    "# If the puuids.txt file exists, read each line of the file and store it in puuids\n",
    "try: \n",
    "    with open(r'./puuids.txt', 'r') as fp:\n",
    "        for line in fp:\n",
    "            puuids.append(line[:-1])\n",
    "        print('Opened file puuids.txt')\n",
    "\n",
    "# If file does not exist, get data from the Riot API\n",
    "except IOError:\n",
    "    SUMMONER_URL = \"https://na1.api.riotgames.com/lol/summoner/v4/summoners/\"\n",
    "    for index, id in enumerate(summonerIds, 1):\n",
    "        # For every 100 requests, wait at least 2 minutes\n",
    "        if index % 100 == 0:\n",
    "            time.sleep(130)\n",
    "\n",
    "        response = requests.get(SUMMONER_URL + id, headers={'X-Riot-Token': API_KEY})\n",
    "        summoner = response.json()\n",
    "        puuids.append(summoner['puuid'])\n",
    "\n",
    "    # Create a new file with the puuids\n",
    "    with open(r'./puuids.txt', 'w+') as fp:\n",
    "        for puuid in puuids:\n",
    "            fp.write(f\"{puuid}\\n\")\n",
    "        print('Created new file puuids.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened file match_ids.txt\n"
     ]
    }
   ],
   "source": [
    "# Use set for matchIds as we do not want to store duplicate matches\n",
    "matchIds = set()\n",
    "\n",
    "# If the match_ids.txt file exists, read each line of the file and store it in matchIds\n",
    "try:\n",
    "    with open(r'./match_ids.txt', 'r') as fp:\n",
    "        for line in fp:\n",
    "            matchIds.add(line[:-1])\n",
    "        print('Opened file match_ids.txt')\n",
    "\n",
    "# If file does not exist, get data from the Riot API\n",
    "except IOError:\n",
    "    MATCHIDS_URL = lambda x : f\"https://americas.api.riotgames.com/lol/match/v5/matches/by-puuid/{x}/ids?type=ranked&start=0&count=100\"\n",
    "    for index, puuid in enumerate(puuids, 1):\n",
    "        # For every 100 requests, wait at least 2 minutes\n",
    "        if index % 100 == 0:\n",
    "            time.sleep(130)\n",
    "\n",
    "        response = requests.get(MATCHIDS_URL(puuid), headers={'X-Riot-Token': API_KEY})\n",
    "        matches = response.json()\n",
    "        matchIds.update(matches)\n",
    "\n",
    "    # Create a new file with the match_ids\n",
    "    with open(r'./match_ids.txt', 'w+') as fp:\n",
    "        for matchId in matchIds:\n",
    "            fp.write(f\"{matchId}\\n\")\n",
    "        print('Created new file match_ids.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened file team_data.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "teams_data = [] \n",
    "\n",
    "# If the team_data.csv file exists, read the csv file and store each row as a dict in teams_data\n",
    "try:\n",
    "    with open(r'./team_data.csv', 'r') as fp:\n",
    "        csvFile = csv.DictReader(fp)\n",
    "\n",
    "        for line in csvFile:\n",
    "            teams_data.append(dict(line))\n",
    "        print('Opened file team_data.txt')\n",
    "\n",
    "# If file does not exist, get data from Riot API\n",
    "except IOError:\n",
    "    MATCHDATA_URL = lambda x : f\"https://americas.api.riotgames.com/lol/match/v5/matches/{x}\"\n",
    "    \n",
    "    # Column names\n",
    "    fieldnames = [\n",
    "        'match_id',\n",
    "        'team1_champ_kills',\n",
    "        'team1_baron_kills', \n",
    "        'team1_drag_kills', \n",
    "        'team1_herald_kills',\n",
    "        'team1_tower_kills',\n",
    "        'team1_inhib_kills',\n",
    "        'team1_total_gold',\n",
    "        'team1_total_dmg',\n",
    "        'team1_win',\n",
    "        'team2_champ_kills',\n",
    "        'team2_baron_kills', \n",
    "        'team2_drag_kills', \n",
    "        'team2_herald_kills',\n",
    "        'team2_tower_kills',\n",
    "        'team2_inhib_kills',\n",
    "        'team2_total_gold',\n",
    "        'team2_total_dmg',\n",
    "        'team2_win'\n",
    "        ]\n",
    "    for index, matchId in enumerate(matchIds, 1):\n",
    "        # Get only the first 10,000 matches\n",
    "        if index == 10_000:\n",
    "            break\n",
    "\n",
    "        # For every 100 requests, wait at least 2 minutes\n",
    "        if index % 100 == 0:\n",
    "            time.sleep(130)\n",
    "\n",
    "        response = requests.get(MATCHDATA_URL(matchId), headers={'X-Riot-Token': API_KEY})\n",
    "        match_data = response.json()\n",
    "\n",
    "        team_data = {}\n",
    "        # Only get data if the 'info' field exists\n",
    "        if 'info' in match_data:\n",
    "            team_data['match_id'] = matchId\n",
    "\n",
    "            # Get information from the 'teams' field in the 'info' field\n",
    "            teams = match_data['info']['teams']\n",
    "            team1 = teams[0]\n",
    "            team_data['team1_champ_kills'] = team1['objectives']['champion']['kills']\n",
    "            team_data['team1_baron_kills'] = team1['objectives']['baron']['kills']\n",
    "            team_data['team1_drag_kills'] = team1['objectives']['dragon']['kills']\n",
    "            team_data['team1_herald_kills'] = team1['objectives']['riftHerald']['kills']\n",
    "            team_data['team1_tower_kills'] = team1['objectives']['tower']['kills']\n",
    "            team_data['team1_inhib_kills'] = team1['objectives']['inhibitor']['kills']\n",
    "            team_data['team1_win'] = 1 if team1['win'] else 0\n",
    "\n",
    "            team2 = teams[1]\n",
    "            team_data['team2_champ_kills'] = team2['objectives']['champion']['kills']\n",
    "            team_data['team2_baron_kills'] = team2['objectives']['baron']['kills']\n",
    "            team_data['team2_drag_kills'] = team2['objectives']['dragon']['kills']\n",
    "            team_data['team2_herald_kills'] = team2['objectives']['riftHerald']['kills']\n",
    "            team_data['team2_tower_kills'] = team2['objectives']['tower']['kills']\n",
    "            team_data['team2_inhib_kills'] = team2['objectives']['inhibitor']['kills']\n",
    "            team_data['team2_win'] = 1 if team2['win'] else 0\n",
    "\n",
    "            team1_total_gold = 0\n",
    "            team1_total_dmg = 0\n",
    "            team2_total_gold = 0\n",
    "            team2_total_dmg = 0\n",
    "            # Go through each player from the match and add all of the totalDamageDealtToChampions and goldEarned for each team\n",
    "            for p in match_data['info']['participants']:\n",
    "                if p['teamId'] == 100: \n",
    "                    team1_total_gold += p['goldEarned']\n",
    "                    team1_total_dmg += p['totalDamageDealtToChampions']\n",
    "                else:\n",
    "                    team2_total_gold += p['goldEarned']\n",
    "                    team2_total_dmg += p['totalDamageDealtToChampions']\n",
    "\n",
    "            team_data['team1_total_gold'] = team1_total_gold\n",
    "            team_data['team1_total_dmg'] = team1_total_dmg\n",
    "            team_data['team2_total_gold'] = team2_total_gold\n",
    "            team_data['team2_total_dmg'] = team2_total_dmg\n",
    "\n",
    "            teams_data.append(team_data)\n",
    "\n",
    "    # Create a new csv file with the team data\n",
    "    with open(r'./team_data.csv', 'w+', newline='') as fp:\n",
    "        writer = csv.DictWriter(fp, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(teams_data)\n",
    "        print('Created new file team_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 172\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    170\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m130\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(MATCHTIMELINE_URL(matchId), headers\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mX-Riot-Token\u001b[39;49m\u001b[39m'\u001b[39;49m: API_KEY})\n\u001b[1;32m    173\u001b[0m match_timeline \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n\u001b[1;32m    175\u001b[0m team_data \u001b[39m=\u001b[39m defaultdict(\u001b[39mlambda\u001b[39;00m: \u001b[39m0\u001b[39m) \n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 745\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    747\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/urllib3/response.py:623\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 623\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[1;32m    624\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[1;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/urllib3/response.py:818\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    817\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_chunk(amt)\n\u001b[1;32m    819\u001b[0m decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode(\n\u001b[1;32m    820\u001b[0m     chunk, decode_content\u001b[39m=\u001b[39mdecode_content, flush_decoder\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    821\u001b[0m )\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m decoded:\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/urllib3/response.py:762\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[39melif\u001b[39;00m amt \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left:\n\u001b[0;32m--> 762\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49m_safe_read(amt)\n\u001b[1;32m    763\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m-\u001b[39m amt\n\u001b[1;32m    764\u001b[0m     returned_chunk \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:630\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_safe_read\u001b[39m(\u001b[39mself\u001b[39m, amt):\n\u001b[1;32m    624\u001b[0m     \u001b[39m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[1;32m    626\u001b[0m \u001b[39m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m<\u001b[39m amt:\n\u001b[1;32m    632\u001b[0m         \u001b[39mraise\u001b[39;00m IncompleteRead(data, amt\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(data))\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "teams_data = [] \n",
    "'''\n",
    "# If the team_data_20.csv file exists, read the csv file and store each row as a dict in teams_data\n",
    "try:\n",
    "    with open(r'./team_data_20.csv', 'r') as fp:\n",
    "        csvFile = csv.DictReader(fp)\n",
    "\n",
    "        for line in csvFile:\n",
    "            teams_data.append(dict(line))\n",
    "        print('Opened file team_data_20.txt')\n",
    "\n",
    "# If file does not exist, get data from Riot API\n",
    "except IOError:\n",
    "    MATCHTIMELINE_URL = lambda x : f\"https://americas.api.riotgames.com/lol/match/v5/matches/{x}/timeline\"\n",
    "    \n",
    "    # Data gathered from start to MAX_TIME (20 minutes)\n",
    "    MAX_TIME = 1_210_000\n",
    "    \n",
    "    # Column names\n",
    "    fieldnames = [\n",
    "        'match_id',\n",
    "        'team1_champ_kills',\n",
    "        'team1_baron_kills',\n",
    "        'team1_drag_kills', \n",
    "        'team1_herald_kills',\n",
    "        'team1_tower_kills',\n",
    "        'team1_inhib_kills',\n",
    "        'team1_total_gold',\n",
    "        'team1_total_dmg',\n",
    "        'team2_champ_kills',\n",
    "        'team2_baron_kills',\n",
    "        'team2_drag_kills', \n",
    "        'team2_herald_kills',\n",
    "        'team2_tower_kills',\n",
    "        'team2_inhib_kills',\n",
    "        'team2_total_gold',\n",
    "        'team2_total_dmg',\n",
    "        ]\n",
    "        \n",
    "    # Participant IDs\n",
    "    TEAM1_IDS = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "    TEAM2_IDS = [\"6\", \"7\", \"8\", \"9\", \"10\"]\n",
    "\n",
    "    for index, matchId in enumerate(matchIds[99:1000], 1):\n",
    "        # Get only the first 10,000 matches\n",
    "        if index == 10_000:\n",
    "            break\n",
    "\n",
    "        # For every 100 requests, wait at least 2 minutes\n",
    "        if index % 100 == 0:\n",
    "            time.sleep(130)\n",
    "\n",
    "        response = requests.get(MATCHTIMELINE_URL(matchId), headers={'X-Riot-Token': API_KEY})\n",
    "        match_timeline = response.json()\n",
    "\n",
    "        team_data = defaultdict(lambda: 0) \n",
    "        # Only get data if the 'info' field exists\n",
    "        if 'info' in match_timeline:\n",
    "            team_data['match_id'] = matchId\n",
    "\n",
    "            frames = match_timeline['info']['frames']\n",
    "            lastFrame = {}\n",
    "            # Go through each frame to get kill data\n",
    "            for frame in frames:\n",
    "                events = frame['events']\n",
    "                timestamp = frame['timestamp']\n",
    "                \n",
    "                if timestamp > MAX_TIME:\n",
    "                    break\n",
    "                \n",
    "                events = frame['events']\n",
    "                for event in events:\n",
    "                    if 'type' not in event:\n",
    "                        continue\n",
    "                    \n",
    "                    match event['type']:\n",
    "                        case 'CHAMPION_KILL':\n",
    "                            if event['killerId'] in range(1, 6):\n",
    "                                team_data['team1_champ_kills'] += 1 \n",
    "                            elif event['killerId'] in range(6, 11):\n",
    "                                team_data['team2_champ_kills'] += 1\n",
    "                        \n",
    "                        case 'ELITE_MONSTER_KILL':\n",
    "                            if event['killerTeamId'] == 100:\n",
    "                                team_data[f\"team1_{event['monsterType']}\"] += 1\n",
    "                            elif event['killerTeamId'] == 200:\n",
    "                                team_data[f\"team2_{event['monsterType']}\"] += 1\n",
    "                            \n",
    "                        case 'BUILDING_KILL':\n",
    "                            if event['teamId'] == 200:\n",
    "                                team_data[f\"team1_{event['buildingType']}\"] += 1\n",
    "                            elif event['teamId'] == 100:\n",
    "                                team_data[f\"team2_{event['buildingType']}\"] += 1\n",
    "                             \n",
    "            # Rename dictionary key names to correct csv column names\n",
    "            new_key_names = [\n",
    "                ('team1_drag_kills', 'team1_DRAGON'), \n",
    "                ('team1_herald_kills', 'team1_RIFTHERALD'), \n",
    "                ('team1_baron_kills', 'team1_BARON_NASHOR'), \n",
    "                ('team1_tower_kills', 'team1_TOWER_BUILDING'),\n",
    "                ('team1_inhib_kills', 'team1_INHIBITOR_BUILDING'),\n",
    "                ('team2_drag_kills', 'team2_DRAGON'), \n",
    "                ('team2_baron_kills', 'team2_BARON_NASHOR'), \n",
    "                ('team2_herald_kills', 'team2_RIFTHERALD'), \n",
    "                ('team2_tower_kills', 'team2_TOWER_BUILDING'),\n",
    "                ('team2_inhib_kills', 'team2_INHIBITOR_BUILDING')\n",
    "                ]\n",
    "                    \n",
    "            for new, old in new_key_names:\n",
    "                team_data[new] = team_data.pop(old, 0)\n",
    "                 \n",
    "            lastFrame = frame\n",
    "\n",
    "            # Get the total gold for each team\n",
    "            participants = lastFrame['participantFrames']\n",
    "            for id in TEAM1_IDS:\n",
    "                team_data['team1_total_gold'] += participants[id]['totalGold']\n",
    "\n",
    "            for id in TEAM2_IDS:\n",
    "                team_data['team2_total_gold'] += participants[id]['totalGold']\n",
    "            \n",
    "            teams_data.append(team_data)\n",
    "    # Create a new csv file with the team data\n",
    "    with open(r'./team_data_20.csv', 'w+', newline='') as fp:\n",
    "        writer = csv.DictWriter(fp, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(teams_data)\n",
    "        print('Created new file team_data_20.csv')\n",
    "    '''\n",
    "\n",
    "MATCHTIMELINE_URL = lambda x : f\"https://americas.api.riotgames.com/lol/match/v5/matches/{x}/timeline\"\n",
    "\n",
    "# Data gathered from start to MAX_TIME (20 minutes)\n",
    "MAX_TIME = 1_210_000\n",
    "\n",
    "# Column names\n",
    "fieldnames = [\n",
    "    'match_id',\n",
    "    'team1_champ_kills',\n",
    "    'team1_baron_kills',\n",
    "    'team1_drag_kills', \n",
    "    'team1_herald_kills',\n",
    "    'team1_tower_kills',\n",
    "    'team1_inhib_kills',\n",
    "    'team1_total_gold',\n",
    "    'team1_total_dmg',\n",
    "    'team2_champ_kills',\n",
    "    'team2_baron_kills',\n",
    "    'team2_drag_kills', \n",
    "    'team2_herald_kills',\n",
    "    'team2_tower_kills',\n",
    "    'team2_inhib_kills',\n",
    "    'team2_total_gold',\n",
    "    'team2_total_dmg',\n",
    "    ]\n",
    "    \n",
    "# Participant IDs\n",
    "TEAM1_IDS = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "TEAM2_IDS = [\"6\", \"7\", \"8\", \"9\", \"10\"]\n",
    "\n",
    "for index, matchId in enumerate(list(matchIds)[99:1000], 1):\n",
    "    # Get only the first 10,000 matches\n",
    "    if index == 10_000:\n",
    "        break\n",
    "\n",
    "    # For every 100 requests, wait at least 2 minutes\n",
    "    if index % 100 == 0:\n",
    "        time.sleep(130)\n",
    "\n",
    "    response = requests.get(MATCHTIMELINE_URL(matchId), headers={'X-Riot-Token': API_KEY})\n",
    "    match_timeline = response.json()\n",
    "\n",
    "    team_data = defaultdict(lambda: 0) \n",
    "    # Only get data if the 'info' field exists\n",
    "    if 'info' in match_timeline:\n",
    "        team_data['match_id'] = matchId\n",
    "\n",
    "        frames = match_timeline['info']['frames']\n",
    "        lastFrame = {}\n",
    "        # Go through each frame to get kill data\n",
    "        for frame in frames:\n",
    "            events = frame['events']\n",
    "            timestamp = frame['timestamp']\n",
    "            \n",
    "            if timestamp > MAX_TIME:\n",
    "                break\n",
    "            \n",
    "            events = frame['events']\n",
    "            for event in events:\n",
    "                if 'type' not in event:\n",
    "                    continue\n",
    "                \n",
    "                match event['type']:\n",
    "                    case 'CHAMPION_KILL':\n",
    "                        if event['killerId'] in range(1, 6):\n",
    "                            team_data['team1_champ_kills'] += 1 \n",
    "                        elif event['killerId'] in range(6, 11):\n",
    "                            team_data['team2_champ_kills'] += 1\n",
    "                    \n",
    "                    case 'ELITE_MONSTER_KILL':\n",
    "                        if event['killerTeamId'] == 100:\n",
    "                            team_data[f\"team1_{event['monsterType']}\"] += 1\n",
    "                        elif event['killerTeamId'] == 200:\n",
    "                            team_data[f\"team2_{event['monsterType']}\"] += 1\n",
    "                        \n",
    "                    case 'BUILDING_KILL':\n",
    "                        if event['teamId'] == 200:\n",
    "                            team_data[f\"team1_{event['buildingType']}\"] += 1\n",
    "                        elif event['teamId'] == 100:\n",
    "                            team_data[f\"team2_{event['buildingType']}\"] += 1\n",
    "                            \n",
    "        # Rename dictionary key names to correct csv column names\n",
    "        new_key_names = [\n",
    "            ('team1_drag_kills', 'team1_DRAGON'), \n",
    "            ('team1_herald_kills', 'team1_RIFTHERALD'), \n",
    "            ('team1_baron_kills', 'team1_BARON_NASHOR'), \n",
    "            ('team1_tower_kills', 'team1_TOWER_BUILDING'),\n",
    "            ('team1_inhib_kills', 'team1_INHIBITOR_BUILDING'),\n",
    "            ('team2_drag_kills', 'team2_DRAGON'), \n",
    "            ('team2_baron_kills', 'team2_BARON_NASHOR'), \n",
    "            ('team2_herald_kills', 'team2_RIFTHERALD'), \n",
    "            ('team2_tower_kills', 'team2_TOWER_BUILDING'),\n",
    "            ('team2_inhib_kills', 'team2_INHIBITOR_BUILDING')\n",
    "            ]\n",
    "                \n",
    "        for new, old in new_key_names:\n",
    "            team_data[new] = team_data.pop(old, 0)\n",
    "                \n",
    "        lastFrame = frame\n",
    "\n",
    "        # Get the total gold for each team\n",
    "        participants = lastFrame['participantFrames']\n",
    "        for id in TEAM1_IDS:\n",
    "            team_data['team1_total_gold'] += participants[id]['totalGold']\n",
    "\n",
    "        for id in TEAM2_IDS:\n",
    "            team_data['team2_total_gold'] += participants[id]['totalGold']\n",
    "        \n",
    "        teams_data.append(team_data)\n",
    "\n",
    "with open(r'./team_data_20.csv', 'a', newline='') as fp:\n",
    "    writer = csv.DictWriter(fp)\n",
    "    writer.writerows(teams_data)\n",
    "    print(f'Added {len(teams_data)} rows to file team_data_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>team1_champ_kills</th>\n",
       "      <th>team1_baron_kills</th>\n",
       "      <th>team1_drag_kills</th>\n",
       "      <th>team1_herald_kills</th>\n",
       "      <th>team1_tower_kills</th>\n",
       "      <th>team1_inhib_kills</th>\n",
       "      <th>team1_total_gold</th>\n",
       "      <th>team1_total_dmg</th>\n",
       "      <th>team1_win</th>\n",
       "      <th>team2_champ_kills</th>\n",
       "      <th>team2_baron_kills</th>\n",
       "      <th>team2_drag_kills</th>\n",
       "      <th>team2_herald_kills</th>\n",
       "      <th>team2_tower_kills</th>\n",
       "      <th>team2_inhib_kills</th>\n",
       "      <th>team2_total_gold</th>\n",
       "      <th>team2_total_dmg</th>\n",
       "      <th>team2_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA1_4483113790</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39804</td>\n",
       "      <td>46021</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34135</td>\n",
       "      <td>35102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NA1_4479019847</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>70457</td>\n",
       "      <td>105986</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>54564</td>\n",
       "      <td>67028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NA1_4446476783</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26115</td>\n",
       "      <td>32100</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32752</td>\n",
       "      <td>37224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NA1_4511030500</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>58437</td>\n",
       "      <td>86769</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44930</td>\n",
       "      <td>49208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NA1_4468860918</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50589</td>\n",
       "      <td>93187</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>62969</td>\n",
       "      <td>99975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         match_id  team1_champ_kills  team1_baron_kills  team1_drag_kills  \\\n",
       "0  NA1_4483113790                 15                  0                 1   \n",
       "1  NA1_4479019847                 44                  2                 2   \n",
       "2  NA1_4446476783                  7                  0                 0   \n",
       "3  NA1_4511030500                 30                  1                 3   \n",
       "4  NA1_4468860918                 20                  0                 1   \n",
       "\n",
       "   team1_herald_kills  team1_tower_kills  team1_inhib_kills  team1_total_gold  \\\n",
       "0                   2                  2                  0             39804   \n",
       "1                   2                  9                  1             70457   \n",
       "2                   1                  1                  0             26115   \n",
       "3                   2                  9                  1             58437   \n",
       "4                   2                  2                  0             50589   \n",
       "\n",
       "   team1_total_dmg  team1_win  team2_champ_kills  team2_baron_kills  \\\n",
       "0            46021          1                 11                  0   \n",
       "1           105986          1                 26                  0   \n",
       "2            32100          0                 20                  0   \n",
       "3            86769          1                 16                  0   \n",
       "4            93187          0                 34                  1   \n",
       "\n",
       "   team2_drag_kills  team2_herald_kills  team2_tower_kills  team2_inhib_kills  \\\n",
       "0                 1                   0                  1                  0   \n",
       "1                 1                   0                  2                  0   \n",
       "2                 2                   0                  3                  0   \n",
       "3                 0                   0                  1                  0   \n",
       "4                 3                   0                 10                  2   \n",
       "\n",
       "   team2_total_gold  team2_total_dmg  team2_win  \n",
       "0             34135            35102          0  \n",
       "1             54564            67028          0  \n",
       "2             32752            37224          1  \n",
       "3             44930            49208          0  \n",
       "4             62969            99975          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./team_data_20.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
